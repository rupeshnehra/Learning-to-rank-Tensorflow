{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import tensorflow_ranking as tfr\n",
    "import tensorboard\n",
    "from sklearn.model_selection import KFold\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "tf.enable_eager_execution()\n",
    "tf.executing_eagerly()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = open(\"/Users/apple/Downloads/libsvm_0_1000\", 'r')\n",
    "\n",
    "# # converting data into readable fomat\n",
    "dataread = data.readlines()\n",
    "\n",
    "# creating files for training and test spliting\n",
    "data_train = open(\"/Users/apple/Downloads/libsvm15-train-1000.txt\", 'w') \n",
    "data_test = open(\"/Users/apple/Downloads/libsvm15-test-1000.txt\", 'w')\n",
    "\n",
    "# spliting dataset into test and training\n",
    "\n",
    "data_train_out = [] \n",
    "data_test_out = []\n",
    "\n",
    "for line in range(0, int(len(dataread)*0.8)): \n",
    "    data_train_out.append(dataread[line]) \n",
    "for line in range(int(len(dataread)*0.8), len(dataread)): \n",
    "    data_test_out.append(dataread[line])\n",
    "\n",
    "for item in data_train_out: \n",
    "    data_train.write(item)\n",
    "\n",
    "for item in data_test_out: \n",
    "    data_test.write(item) \n",
    "\n",
    "data_train.close() \n",
    "data_test.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Input Data\n",
    "\n",
    "_TRAIN_DATA_PATH= \"/Users/apple/Downloads/libsvm15-train-1000.txt\"\n",
    "_TEST_DATA_PATH= \"/Users/apple/Downloads/libsvm15-test-1000.txt\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model Parameters \n",
    "\n",
    "_LOSS=\"pairwise_logistic_loss\"\n",
    "         \n",
    "# no. of pairs\n",
    "\n",
    "_LIST_SIZE=500 \n",
    "\n",
    "_NUM_FEATURES=46\n",
    "\n",
    "_BATCH_SIZE= 100 \n",
    "\n",
    "_HIDDEN_LAYER_DIMS=[\"128\",\"64\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#input pipeline for tensorflow data object\n",
    "\n",
    "def input_fn(path):\n",
    "  train_dataset = tf.data.Dataset.from_generator(\n",
    "      tfr.data.libsvm_generator(path, _NUM_FEATURES, _LIST_SIZE),\n",
    "      output_types=(\n",
    "          {str(k): tf.float32 for k in range(1,_NUM_FEATURES+1)},\n",
    "          tf.float32\n",
    "      ),\n",
    "      output_shapes=(\n",
    "          {str(k): tf.TensorShape([_LIST_SIZE, 1])\n",
    "            for k in range(1,_NUM_FEATURES+1)},\n",
    "          tf.TensorShape([_LIST_SIZE])\n",
    "      )\n",
    "  )\n",
    "\n",
    "  train_dataset = train_dataset.shuffle(500).repeat().batch(_BATCH_SIZE)\n",
    "#   train_dataset = train_dataset.repeat().batch(_BATCH_SIZE)  \n",
    "  return train_dataset.make_one_shot_iterator().get_next()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scoring function of tensorflow model\n",
    "\n",
    "def example_feature_columns():\n",
    "  \"\"\"Returns the example feature columns.\"\"\"\n",
    "  feature_names = [\n",
    "      \"%d\" % (i + 1) for i in range(0, _NUM_FEATURES)\n",
    "  ]\n",
    "  return {\n",
    "      name: tf.feature_column.numeric_column(\n",
    "          name, shape=(1,), default_value=0.0) for name in feature_names\n",
    "  }\n",
    "\n",
    "def make_score_fn():\n",
    "  \"\"\"Returns a scoring function to build `EstimatorSpec`.\"\"\"\n",
    "\n",
    "  def _score_fn(context_features, group_features, mode, params, config):\n",
    "    \"\"\"Defines the network to score a documents.\"\"\"\n",
    "    del params\n",
    "    del config\n",
    "    # Define input layer.\n",
    "    example_input = [\n",
    "        tf.layers.flatten(group_features[name])\n",
    "        for name in sorted(example_feature_columns())\n",
    "    ]\n",
    "    input_layer = tf.concat(example_input, 1)\n",
    "\n",
    "    cur_layer = input_layer\n",
    "    for i, layer_width in enumerate(int(d) for d in _HIDDEN_LAYER_DIMS):\n",
    "      cur_layer = tf.layers.dense(\n",
    "          cur_layer,\n",
    "          units=layer_width,\n",
    "          activation=\"tanh\")\n",
    "\n",
    "    logits = tf.layers.dense(cur_layer, units=1)\n",
    "    \n",
    "    return logits\n",
    "\n",
    "  return _score_fn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluation metrics\n",
    "\n",
    "def eval_metric_fns():\n",
    "  \"\"\"Returns a dict from name to metric functions.\n",
    "\n",
    "  Returns:\n",
    "    A dict mapping from metric name to a metric function with above signature.\n",
    "  \"\"\"\n",
    "  metric_fns = {}\n",
    "  metric_fns.update({\n",
    "      \"metric/ndcg@%d\" % topn: tfr.metrics.make_ranking_metric_fn(\n",
    "          tfr.metrics.RankingMetricKey.NDCG, topn=topn)\n",
    "      for topn in [1, 3, 5, 10, 50]\n",
    "  })\n",
    "  \n",
    "  metric_fns.update({\n",
    "      \"metric/%s\" % name: tfr.metrics.make_ranking_metric_fn(name) for name in [\n",
    "          tfr.metrics.RankingMetricKey.ARP,\n",
    "          tfr.metrics.RankingMetricKey.ORDERED_PAIR_ACCURACY,\n",
    "      ]\n",
    "  })\n",
    "\n",
    "  return metric_fns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Building model estimators and parameters\n",
    "\n",
    "def get_estimator(hparams):\n",
    "  \"\"\"Create a ranking estimator.\n",
    "\n",
    "  Args:\n",
    "    hparams: (tf.contrib.training.HParams) a hyperparameters object.\n",
    "\n",
    "  Returns:\n",
    "    tf.learn `Estimator`.\n",
    "  \"\"\"\n",
    "  def _train_op_fn(loss):\n",
    "    \"\"\"Defines train op used in ranking head.\"\"\"\n",
    "    return tf.contrib.layers.optimize_loss(\n",
    "        loss=loss,\n",
    "        global_step=tf.train.get_global_step(),\n",
    "        learning_rate=hparams.learning_rate,\n",
    "        optimizer=\"Adagrad\")\n",
    "\n",
    "  ranking_head = tfr.head.create_ranking_head(\n",
    "      loss_fn=tfr.losses.make_loss_fn(_LOSS),\n",
    "      eval_metric_fns=eval_metric_fns(),\n",
    "      train_op_fn=_train_op_fn)\n",
    "  \n",
    "  return tf.estimator.Estimator(\n",
    "      model_fn=tfr.model.make_groupwise_ranking_fn(\n",
    "          group_score_fn=make_score_fn(),\n",
    "          group_size=1,\n",
    "          transform_fn=None,\n",
    "          ranking_head=ranking_head),\n",
    "      params=hparams)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Using default config.\n",
      "WARNING:tensorflow:Using temporary folder as model directory: /var/folders/7y/q_djqpds69b8kfns_7r6xvb40000gn/T/tmps8euk12p\n",
      "INFO:tensorflow:Using config: {'_model_dir': '/var/folders/7y/q_djqpds69b8kfns_7r6xvb40000gn/T/tmps8euk12p', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': allow_soft_placement: true\n",
      "graph_options {\n",
      "  rewrite_options {\n",
      "    meta_optimizer_iterations: ONE\n",
      "  }\n",
      "}\n",
      ", '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x1c3e8d8f28>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}\n"
     ]
    }
   ],
   "source": [
    "# Initializing estimator\n",
    "\n",
    "hparams = tf.contrib.training.HParams(learning_rate=0.1)\n",
    "ranker = get_estimator(hparams)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /anaconda3/lib/python3.7/site-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "WARNING:tensorflow:From /anaconda3/lib/python3.7/site-packages/tensorflow/python/data/ops/dataset_ops.py:429: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "tf.py_func is deprecated in TF V2. Instead, use\n",
      "    tf.py_function, which takes a python function which manipulates tf eager\n",
      "    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to\n",
      "    an ndarray (just call tensor.numpy()) but having access to eager tensors\n",
      "    means `tf.py_function`s can use accelerators such as GPUs as well as\n",
      "    being differentiable using a gradient tape.\n",
      "    \n",
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Use groupwise dnn v2.\n",
      "WARNING:tensorflow:From /Users/apple/.local/lib/python3.7/site-packages/tensorflow_ranking/python/model.py:102: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "WARNING:tensorflow:From <ipython-input-6-da0becb30c8a>:23: flatten (from tensorflow.python.layers.core) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use keras.layers.flatten instead.\n",
      "WARNING:tensorflow:From <ipython-input-6-da0becb30c8a>:32: dense (from tensorflow.python.layers.core) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use keras.layers.dense instead.\n",
      "WARNING:tensorflow:From /Users/apple/.local/lib/python3.7/site-packages/tensorflow_ranking/python/model.py:268: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.7/site-packages/tensorflow/python/ops/gradients_impl.py:110: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Saving checkpoints for 0 into /var/folders/7y/q_djqpds69b8kfns_7r6xvb40000gn/T/tmps8euk12p/model.ckpt.\n",
      "INFO:tensorflow:loss = 0.94437134, step = 1\n",
      "INFO:tensorflow:Saving checkpoints for 100 into /var/folders/7y/q_djqpds69b8kfns_7r6xvb40000gn/T/tmps8euk12p/model.ckpt.\n",
      "INFO:tensorflow:Loss for final step: 0.020769034.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow_estimator.python.estimator.estimator.Estimator at 0x1c3e8d80f0>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Training model\n",
    "\n",
    "ranker.train(input_fn=lambda: input_fn(_TRAIN_DATA_PATH), steps=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Use groupwise dnn v2.\n",
      "WARNING:tensorflow:From /Users/apple/.local/lib/python3.7/site-packages/tensorflow_ranking/python/metrics.py:152: div (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Deprecated in favor of operator or tf.math.divide.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Starting evaluation at 2019-06-03T06:58:50Z\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "WARNING:tensorflow:From /anaconda3/lib/python3.7/site-packages/tensorflow/python/training/saver.py:1266: checkpoint_exists (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use standard file APIs to check for files with this prefix.\n",
      "INFO:tensorflow:Restoring parameters from /var/folders/7y/q_djqpds69b8kfns_7r6xvb40000gn/T/tmps8euk12p/model.ckpt-100\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Evaluation [10/100]\n",
      "INFO:tensorflow:Evaluation [20/100]\n",
      "INFO:tensorflow:Evaluation [30/100]\n",
      "INFO:tensorflow:Evaluation [40/100]\n",
      "INFO:tensorflow:Evaluation [50/100]\n",
      "INFO:tensorflow:Evaluation [60/100]\n",
      "INFO:tensorflow:Evaluation [70/100]\n",
      "INFO:tensorflow:Evaluation [80/100]\n",
      "INFO:tensorflow:Evaluation [90/100]\n",
      "INFO:tensorflow:Evaluation [100/100]\n",
      "INFO:tensorflow:Finished evaluation at 2019-06-03-07:06:34\n",
      "INFO:tensorflow:Saving dict for global step 100: global_step = 100, labels_mean = 0.0026331, logits_mean = -5.730587, loss = 0.114178896, metric/arp = 17.443155, metric/ndcg@1 = 0.4520066, metric/ndcg@10 = 0.6344018, metric/ndcg@3 = 0.5566534, metric/ndcg@5 = 0.6031206, metric/ndcg@50 = 0.6700334, metric/ordered_pair_accuracy = 0.9679511\n",
      "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 100: /var/folders/7y/q_djqpds69b8kfns_7r6xvb40000gn/T/tmps8euk12p/model.ckpt-100\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'labels_mean': 0.0026331,\n",
       " 'logits_mean': -5.730587,\n",
       " 'loss': 0.114178896,\n",
       " 'metric/arp': 17.443155,\n",
       " 'metric/ndcg@1': 0.4520066,\n",
       " 'metric/ndcg@10': 0.6344018,\n",
       " 'metric/ndcg@3': 0.5566534,\n",
       " 'metric/ndcg@5': 0.6031206,\n",
       " 'metric/ndcg@50': 0.6700334,\n",
       " 'metric/ordered_pair_accuracy': 0.9679511,\n",
       " 'global_step': 100}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Evaluating model on test \n",
    "\n",
    "ranker.evaluate(input_fn=lambda: input_fn(_TEST_DATA_PATH), steps=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sess = tf.Session()\n",
    "# file_writer = tf.summary.FileWriter('/anaconda3/pkgs/tensorboard-1.13.1-py37haf313ee_0/lib/python3.7/site-packages/tensorboard/logs', sess.graph)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "make_score_fn()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sess = tf.Session()\n",
    "with tf.Session() as sess:\n",
    "\n",
    "    print(sess.run(logits, feed_dict=feed_dict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
